## Discover, Measure, and Mitigate Bias in Loan Data

## Project Overview

This project aims to address fairness in AI by exploring, measuring, and mitigating bias in a hypothetical loan processing dataset. The initiative is rooted in the belief that fairness in AI requires careful planning to handle differences in data, ensuring that outcomes are representative of the developers' actual goals. This project divides the task into three key sections: discovering data imbalances, measuring biases using various statistical metrics, and implementing techniques to mitigate these biases.

## Project Structure

- **Part 1: Discover Imbalance**
  - Explore the dataset to identify biased subgroups.

- **Part 2: Measure Bias**
  - Employ various metrics such as Statistical Parity, Odds Ratio, Equal Opportunity Difference, and Disparate Impact to quantify bias.

- **Part 3: Mitigate Bias**
  - Implement and compare several strategies to mitigate bias:
    - Baseline Logistic Regression on unbalanced data
    - Logistic Regression with Re-Weighting
    - Generating Synthetic Samples with SMOTE
    - Logistic Regression with SMOTE
    - Logistic Regression with SMOTE and Re-Weighting
    - Aggregated Classification Reports for comparison

## Results

The project successfully identifies, quantifies, and mitigates biases within the dataset. Each technique applied offers a different perspective on bias reduction, and their effectiveness is documented clearly throughout the project.

## Conclusion

Through careful analysis and the application of various mitigation strategies, this project demonstrates effective ways to enhance fairness in AI algorithms used in financial settings. The comparative results highlight the importance of incorporating ethical considerations in AI development to prevent societal harms.
